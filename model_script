import random
import numpy as np
import pandas as pd
import torch
import spacy
from sklearn.metrics import classification_report
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from imblearn.over_sampling import RandomOverSampler
from datasets import load_dataset
from huggingface_hub import login, Repository
from tqdm.auto import tqdm

def set_seed(seed_value=42):
    random.seed(seed_value)
    np.random.seed(seed_value)
    torch.manual_seed(seed_value)
    torch.cuda.manual_seed_all(seed_value)

set_seed(42)

LR = 5e-5
EPS = 1e-8
EPOCHS = 50
BATCH_SIZE = 32
ACCUMULATION_STEPS = 4
MAX_LEN = 128
EARLY_STOPPING_PATIENCE = 10

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Log in to Hugging Face
login(token='YOUR_HF_TOKEN')  # Replace 'YOUR_HF_TOKEN' with your actual Hugging Face token

# Load dataset from Hugging Face
dataset = load_dataset('onekat/literalmente-dataset')

# Concatenate splits into a single DataFrame for processing
df_train = pd.DataFrame(dataset['train'])
df_validation = pd.DataFrame(dataset['validation'])
df_test = pd.DataFrame(dataset['test'])

df = pd.concat([df_train, df_validation, df_test], ignore_index=True)

# Assuming labels are as follows:
# 0: Etymological
# 1: Intensifier
# 2: Emphatic

# Map label indices to label names
label_names = {0: 'Etymological', 1: 'Intensifier', 2: 'Emphatic'}
df['sentido'] = df['label'].map(label_names)

# Load spaCy and extract sentences containing 'literalmente'
nlp = spacy.load('es_core_news_sm')

def extract_literalmente_sentence(text):
    doc = nlp(text)
    sentences_with_literalmente = []
    for sent in doc.sents:
        if 'literalmente' in sent.text.lower():
            sentences_with_literalmente.append(sent.text.strip())
    return ' '.join(sentences_with_literalmente)

# Apply the function
df['text_literalmente'] = df['text'].apply(extract_literalmente_sentence)

# Remove rows without sentences containing 'literalmente'
df = df[df['text_literalmente'].str.strip() != '']

model_label_configs = {
    'Model_1': {
        'labels_to_include': ['Etymological', 'Intensifier', 'Emphatic'],
        'label_mapping': {'Etymological': 0, 'Intensifier': 1, 'Emphatic': 2}
    },
    'Model_2': {
        'labels_to_include': ['Intensifier', 'Emphatic'],
        'label_mapping': {'Intensifier': 0, 'Emphatic': 1}
    },
    'Model_3': {
        'labels_to_include': ['Etymological', 'Intensifier'],
        'label_mapping': {'Etymological': 0, 'Intensifier': 1}
    },
    'Model_4': {
        'labels_to_include': ['Etymological', 'Emphatic'],
        'label_mapping': {'Etymological': 0, 'Emphatic': 1}
    },
    'Model_5': {
        'labels_to_include': ['Etymological', 'Intensifier', 'Emphatic'],
        'label_mapping': {'Etymological': 0, 'Intensifier': 1, 'Emphatic': 1}
    },
    'Model_6': {
        'labels_to_include': ['Etymological', 'Intensifier', 'Emphatic'],
        'label_mapping': {'Etymological': 0, 'Intensifier': 1, 'Emphatic': 0}
    },
}

tokenizer = BertTokenizerFast.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased', do_lower_case=True)

def tokenize_data(sentences, labels):
    inputs = tokenizer(
        list(sentences),
        add_special_tokens=True,
        max_length=MAX_LEN,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )
    return inputs['input_ids'], inputs['attention_mask'], torch.tensor(labels)

def create_dataloader(inputs, masks, labels, sampler):
    data = TensorDataset(inputs, masks, labels)
    return DataLoader(data, sampler=sampler(data), batch_size=BATCH_SIZE)

def train_and_evaluate(model_name, label_config):
    print(f"\nTraining {model_name}...\n")
    df_model = df.copy()
    df_model = df_model[df_model['sentido'].isin(label_config['labels_to_include'])]
    df_model['label_mapped'] = df_model['sentido'].map(label_config['label_mapping'])
    df_model.dropna(subset=['text_literalmente', 'label_mapped'], inplace=True)
    sentences = df_model['text_literalmente'].tolist()
    labels = df_model['label_mapped'].tolist()
    temp_df = pd.DataFrame({'text': sentences, 'label': labels})
    ros = RandomOverSampler(random_state=42)
    X_resampled, y_resampled = ros.fit_resample(temp_df[['text']], temp_df['label'])
    sentences_resampled = X_resampled['text'].tolist()
    labels_resampled = y_resampled.tolist()
    sentences_resampled = np.array(sentences_resampled)
    labels_resampled = np.array(labels_resampled)
    X_train, X_temp, y_train, y_temp = train_test_split(
        sentences_resampled, labels_resampled, test_size=0.2, random_state=42, stratify=labels_resampled)
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)
    print(f"Number of training samples: {len(X_train)}")
    print(f"Number of validation samples: {len(X_val)}")
    print(f"Number of test samples: {len(X_test)}")
    train_inputs, train_masks, train_labels = tokenize_data(X_train, y_train)
    val_inputs, val_masks, val_labels = tokenize_data(X_val, y_val)
    test_inputs, test_masks, test_labels = tokenize_data(X_test, y_test)
    train_dataloader = create_dataloader(train_inputs, train_masks, train_labels, RandomSampler)
    val_dataloader = create_dataloader(val_inputs, val_masks, val_labels, SequentialSampler)
    test_dataloader = create_dataloader(test_inputs, test_masks, test_labels, SequentialSampler)
    num_labels = len(set(label_config['label_mapping'].values()))
    model = BertForSequenceClassification.from_pretrained(
        'dccuchile/bert-base-spanish-wwm-uncased',
        num_labels=num_labels,
        output_attentions=False,
        output_hidden_states=False,
    )
    model.to(device)
    optimizer = AdamW(model.parameters(), lr=LR, eps=EPS)
    total_steps = len(train_dataloader) * EPOCHS // ACCUMULATION_STEPS
    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)
    best_val_accuracy = 0
    epochs_no_improve = 0
    for epoch in range(EPOCHS):
        model.train()
        total_loss = 0
        optimizer.zero_grad()
        progress_bar = tqdm(train_dataloader, desc=f"Epoch {epoch+1}/{EPOCHS}", leave=False)
        for step, batch in enumerate(progress_bar):
            batch_input_ids = batch[0].to(device)
            batch_input_mask = batch[1].to(device)
            batch_labels = batch[2].to(device)
            outputs = model(batch_input_ids, attention_mask=batch_input_mask, labels=batch_labels)
            loss = outputs.loss / ACCUMULATION_STEPS
            total_loss += loss.item()
            loss.backward()
            if (step + 1) % ACCUMULATION_STEPS == 0 or (step + 1) == len(train_dataloader):
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad()
            progress_bar.set_postfix({'Loss': loss.item() * ACCUMULATION_STEPS})
        avg_train_loss = total_loss / len(train_dataloader)
        model.eval()
        val_preds, val_labels_list = [], []
        with torch.no_grad():
            for batch in val_dataloader:
                batch_input_ids = batch[0].to(device)
                batch_input_mask = batch[1].to(device)
                batch_labels = batch[2].to(device)
                outputs = model(batch_input_ids, attention_mask=batch_input_mask)
                logits = outputs.logits
                preds = torch.argmax(logits, dim=1)
                val_preds.extend(preds.cpu().numpy())
                val_labels_list.extend(batch_labels.cpu().numpy())
        val_accuracy = np.mean(np.array(val_preds) == np.array(val_labels_list))
        print(f"Epoch {epoch + 1}/{EPOCHS} - Average Training Loss: {avg_train_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}")
        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy
            epochs_no_improve = 0
            model_name_hub = f'onekat/{model_name}'
            # Prepare the model card content
            inverse_label_mapping = {v: k for k, v in label_config['label_mapping'].items()}
            target_names = [inverse_label_mapping[i] for i in range(num_labels)]
            # Generate classification report on validation set
            val_classification_report = classification_report(
                val_labels_list, val_preds, target_names=target_names, output_dict=True
            )
            # Prepare the model card metadata
            model_card = f"""
            # {model_name}

            This model is a fine-tuned version of [dccuchile/bert-base-spanish-wwm-uncased](https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased) on a custom dataset.

            ## Hyperparameters

            - Learning Rate: {LR}
            - Epsilon: {EPS}
            - Epochs: {epoch + 1}
            - Batch Size: {BATCH_SIZE}
            - Gradient Accumulation Steps: {ACCUMULATION_STEPS}
            - Max Sequence Length: {MAX_LEN}

            ## Evaluation Results

            **Validation Accuracy:** {val_accuracy:.4f}

            ### Classification Report on Validation Set

            """
            for label in target_names:
                precision = val_classification_report[label]['precision']
                recall = val_classification_report[label]['recall']
                f1_score = val_classification_report[label]['f1-score']
                support = val_classification_report[label]['support']
                model_card += f"- **{label}**\n"
                model_card += f"  - Precision: {precision:.4f}\n"
                model_card += f"  - Recall: {recall:.4f}\n"
                model_card += f"  - F1-score: {f1_score:.4f}\n"
                model_card += f"  - Support: {support}\n\n"

            # Save the model card to a file
            with open("README.md", "w") as f:
                f.write(model_card)
                    # Save the model card to the model directory

           # Initialize or clone the repository
            repo = Repository(local_dir=model_name, clone_from=model_name_hub, use_auth_token='YOUR_HF_TOKEN')

            # Add all files and commit
            repo.git_add()
            repo.git_commit(f"Update model after epoch {epoch + 1}")

            # Push to the Hub
            repo.git_push()

            print(f"Model and README.md pushed to Hugging Face Hub at epoch {epoch + 1} with validation accuracy {val_accuracy:.4f}")


            # Push the model to Hugging Face Hub with the model card
            model.push_to_hub(model_name_hub, token='YOUR_HF_TOKEN')
            tokenizer.push_to_hub(model_name_hub, token='YOUR_HF_TOKEN')
            print(f"Model pushed to Hugging Face Hub at epoch {epoch + 1} with validation accuracy {val_accuracy:.4f}")
        else:
            epochs_no_improve += 1
            if epochs_no_improve >= EARLY_STOPPING_PATIENCE:
                print(f"No improvement in validation accuracy in the last {EARLY_STOPPING_PATIENCE} epochs. Stopping training.")
                break
    print(f"Training of {model_name} completed.")
    # Final evaluation on the test set
    model.eval()
    test_preds, test_labels_list = [], []
    with torch.no_grad():
        for batch in test_dataloader:
            batch_input_ids = batch[0].to(device)
            batch_input_mask = batch[1].to(device)
            batch_labels = batch[2].to(device)
            outputs = model(batch_input_ids, attention_mask=batch_input_mask)
            logits = outputs.logits
            preds = torch.argmax(logits, dim=1)
            test_preds.extend(preds.cpu().numpy())
            test_labels_list.extend(batch_labels.cpu().numpy())
    # Generate classification report on test set
    test_classification_report = classification_report(
        test_labels_list, test_preds, target_names=target_names, output_dict=True
    )
    test_accuracy = np.mean(np.array(test_preds) == np.array(test_labels_list))
    # Update the model card with test results
    model_card += f"## Test Results\n\n**Test Accuracy:** {test_accuracy:.4f}\n\n### Classification Report on Test Set\n\n"
    for label in target_names:
        precision = test_classification_report[label]['precision']
        recall = test_classification_report[label]['recall']
        f1_score = test_classification_report[label]['f1-score']
        support = test_classification_report[label]['support']
        model_card += f"- **{label}**\n"
        model_card += f"  - Precision: {precision:.4f}\n"
        model_card += f"  - Recall: {recall:.4f}\n"
        model_card += f"  - F1-score: {f1_score:.4f}\n"
        model_card += f"  - Support: {support}\n\n"
    # Save the updated model card
    with open("README.md", "w") as f:
        f.write(model_card)
    # Push the updated model card to the hub
    model.push_to_hub(model_name_hub, token='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')
    tokenizer.push_to_hub(model_name_hub, token='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')
    print(f"Updated model card with test results pushed to Hugging Face Hub for {model_name}.")

for model_name, label_config in model_label_configs.items():
    train_and_evaluate(model_name, label_config)

print("Training of all models completed.")
